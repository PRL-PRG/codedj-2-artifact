---
title: "An Empirical Study of Method Chaining in Java"
output: html_notebook
---
FIRST EXECUTE artifact/dataset.Rmd!!!

```{r}
library("rjson")
library("readr")
library("dplyr")
library("ggplot2")
library("tidyverse")
library("GGally")
library(gridExtra)
library("ggeffects")
library(ggrepel)
```


```{r}
# java variable is being draged from artifact/dataset.Rmd
big_dataset = java
big_dataset = big_dataset %>% rename(project_id=id)

# create a column of the year of creation
big_dataset = big_dataset %>% mutate( created_year=format( as.Date( as.POSIXct(created, origin="1970-01-01") ), "%Y" ))

# create a column of the last commit year
big_dataset = big_dataset %>% mutate( last_commit_year=format( as.Date( as.POSIXct(newestCommitTime, origin="1970-01-01") ), "%Y" ))
```

```{r}
big_dataset
```
# Gathering top starred projects

This is our reproduction of what the authors did. 
```{r}
# since there are less than 1k project created in 2008, we gather all of them
df = big_dataset %>% filter(created_year==2008) %>% select(project_id)


for(year_ in 2009:2018) {
  # get top 1k starred projects per year
  df = rbind(df, big_dataset %>% filter(created_year==year_) %>% arrange(-stars) %>% head(1000) %>% select(project_id))  
}


set.seed(43)
df = df %>% sample_n(3000) # random sample 3k of them

# create dataframe to save as csv
all_ids = df$project_id
df = data.frame(snapshot_id=all_ids)

# NOTE: write.csv will generate the column name within quotes. You must remove these quotes.
# write.csv(df,'./reproductions/empirical_method_chaining/top_starred_indices.csv',row.names = FALSE)
```

The djanco query to replicate this query is at 
`./artifacts/empirical_method_chaining/top-starred-sampler`.

# Some helper functions
```{r}
get_project_indices = function(years, method_chainings, is_top=TRUE, seed_=5) {
  # this function is used to sample the valid indices.
  set.seed(seed_)
  if(is_top) {
    # get indices of top starred_projects
    print("is top")
    valid_ids = method_chainings %>% filter(year %in% years)
    valid_ids = valid_ids["project_id"][[1]]
    temp_df = big_dataset %>% filter(project_id %in% valid_ids)
    temp_df = temp_df %>% sample_n(250)
  }else{
    valid_ids = method_chainings %>% filter(year %in% years) %>% distinct(project_id)
    valid_ids = valid_ids["project_id"][[1]]
    return(valid_ids)
  }
  return(temp_df[[1]])
}
```


U(n) is defined as the ratio of projects in a set that have at least 1 method chain
of length $n$.
```{r}
f_un = function(n,projects_indices, method_chainings){
  # computes Un function for a given n and a given set of projects.
  
  y = method_chainings %>% filter(project_id %in% projects_indices & chain_length >= n)
  y = nrow(y %>% distinct(project_id))
  
  total_projects = length(projects_indices)
  
  y = y/total_projects  # return the ratio
  return(y)
}
```

```{r}
get_dataframe_un = function(years,method_chainings_,bottom_n=1, top_n=100, dataset_size_=500, is_top_=TRUE, seed=5) {
  # computes Un for each method chain length
  n_s = c()
  un_s = c()
  c_years = c()
  for(year in years){
    project_indices = get_project_indices(c(year), method_chainings_,is_top=is_top_, seed_=seed) 
    print(paste(year, "DATASET SIZE: ",length(project_indices)))
    for(n in bottom_n:top_n){
        current_un = f_un(n, project_indices, method_chainings_)
        n_s = append(n_s, n)
        un_s = append(un_s, current_un)
        c_years = append(c_years, year)
    }
  }
  return(data.frame(n=n_s, Un=un_s, year=c_years))
}
```


```{r}
get_difference_dataframe = function(df, name_) {
  # returns a dataframe with the difference between Un of 2010 and 2018
  old_values = df %>% filter(year==2010) %>% select(n,  Un) %>% rename(old=Un)
  new_values = df %>% filter(year==2018) %>% select(n,  Un) %>% rename(recent=Un)
  
  new_df = inner_join(old_values, new_values, by="n")
  new_df = new_df %>% mutate(diff=recent-old) %>% mutate(name=name_)
  return(new_df)
}
```


# Load samples

The djanco query to sample and compute the frequencies of chain lengths, i.e the files of the samples we load,
is at `./artifacts/empirical_method_chaining/sampler-by-commit`.


```{r}
for (sample_num in 1:10){
  df_2010 = read_csv(paste('./reproductions/empirical_method_chaining/dev_samples/dev_chain_lengths_2010_',sample_num,'.csv', sep = ""))
  df_2018 = read_csv(paste('./reproductions/empirical_method_chaining/dev_samples/dev_chain_lengths_2018_',sample_num,'.csv', sep = ""))
  
  all = rbind(df_2010, df_2018)
  all_un = get_dataframe_un(c(2010, 2018), all, top_n=150, dataset_size_ = 1700, is_top_ = FALSE)

  p1 <- ggplot(all_un, aes(x=n, y=Un, color=factor(year) )) +
    geom_point() +
    scale_y_continuous(labels = scales::percent,limits=c(0, 1), breaks=c(0, 0.2, 0.4, 0.6,0.8,1)) +
    labs(y= "% of Projects", x = "chain_length") +
    guides(colour=guide_legend(title=""))+ 
    theme(axis.text=element_text(size=20), axis.title=element_text(size=20),
                                  legend.text=element_text(size=16), panel.grid.major = element_blank())
  print(p1)
  # diff_df1 = get_difference_dataframe(all_un1, "sample 1")
}
```


`stars_1_chain_lengths.csv` is the output of running the Djanco query
in `./artifacts/empirical_method_chaining/query_method_chainings`. We used the list of projects ids
at `./artifacts/empirical_method_chaining/top_starred_indices.csv`.
```{r}
# laod the result of our reproduction of the methodology of the authors
stars_method_chainings = read_csv("./reproductions/empirical_method_chaining/stars_1_chain_lengths.csv")
```

```{r}
stars_dataframe = get_dataframe_un(c(2010,2018),stars_method_chainings, top_n=150,seed=777)
pstars <- ggplot(stars_dataframe, aes(x=n, y=Un, color=factor(year) )) +
    geom_point() +
    scale_y_continuous(labels = scales::percent,limits=c(0, 1), breaks=c(0, 0.2, 0.4, 0.6,0.8,1)) +
    labs(y= "% of Projects", x = "chain_length") +
    guides(colour=guide_legend(title=""))+ 
    theme(axis.text=element_text(size=20), axis.title=element_text(size=20),
                                  legend.text=element_text(size=16), panel.grid.major = element_blank()) + 
    ggtitle("Top Starred") 
stars_difference_df  = get_difference_dataframe(stars_dataframe, "Stars")
```

For each sample, and for each chain length we calculate the difference of Un to see if indeed chains lengths have increased. If they have increased the difference should be a positive number.

```{r}
difference_dataframe = stars_difference_df
for (sample_num in 1:10){
  df_2010 = read_csv(paste('./reproductions/empirical_method_chaining/dev_samples/dev_chain_lengths_2010_',sample_num,'.csv', sep = ""))
  df_2018 = read_csv(paste('./reproductions/empirical_method_chaining/dev_samples/dev_chain_lengths_2018_',sample_num,'.csv', sep = ""))
  
  all = rbind(df_2010, df_2018)
  all_un = get_dataframe_un(c(2010, 2018), all, top_n=150, dataset_size_ = 1700, is_top_ = FALSE)
  diff_df = get_difference_dataframe(all_un, paste("Sample", sample_num))
  difference_dataframe = rbind(difference_dataframe, diff_df)
}
```




```{r}
difference_dataframe
```


# Plot difference dataframe
we plot for each sample the difference among U(n). We substract U(n) of 2010 to U(n) of 2018.
```{r}
# difference_dataframe$name = factor(difference_dataframe$name, levels=c("Stars", "sample 1", "sample 2", "sample 3"))
final_plot <- ggplot() + 
  geom_line(data=difference_dataframe%>%filter(name=="Stars" & n<101),size=0.5,aes(x=n, y=diff),color="black") + 
  geom_point(data=difference_dataframe%>%filter(name=="Sample 1" & n<101),size=0.75,aes(x=n, y=diff, color=name))+
  scale_color_brewer(palette = "Dark2") +
  geom_vline(xintercept=8, color="grey", size=0.2) + 
  scale_x_continuous(breaks=c(0,8,25,50,75,100))+
  xlab("")+
  ylab("") +
  theme(panel.background = element_blank(),legend.position = "none",text = element_text(size=20))
final_plot
```

We are interested in the difference of U(8) since we are interested in the affirmation the authors do: 
"Since chains of length 8 are unlikely to be composed by programmers who tend to avoid method chain- ing, this result is another supportive evidence for the widespread use of method chaining.".
The authors obtain for 2010 a U(8)=50.1%, while in 2018 authors obtain a U(8)=42.7%.

```{r}
difference_dataframe %>% filter(n==8)
```


```{r}
# create figure
ggsave("figs/method_chainings/final_graph.pdf", plot=final_plot, height=7, width=10 )
```


# Observation 1

```{r}
get_sum_frequencies = function(df) {
  temp = df %>% mutate(sum=sum(frequency))
  result = temp$sum[1]
  return(result)
}

```


```{r}

df_2010 = stars_method_chainings %>% filter(year==2010)
df_2018 = stars_method_chainings %>% filter(year==2018)
all_frequencies_2010 = get_sum_frequencies(df_2010)
all_frequencies_2018 = get_sum_frequencies(df_2018)
  
frequencies_g2_2010 = get_sum_frequencies(df_2010 %>% filter(chain_length > 1))
frequencies_g2_2018 = get_sum_frequencies(df_2018 %>% filter(chain_length > 1))
print(paste(round(frequencies_g2_2010/all_frequencies_2010,2), round(frequencies_g2_2018/all_frequencies_2018,2)))
```


```{r message=FALSE}
for (sample_num in 1:10){
  df_2010 = read_csv(paste('./reproductions/empirical_method_chaining/dev_samples/dev_chain_lengths_2010_',sample_num,'.csv', sep = ""), )
  df_2018 = read_csv(paste('./reproductions/empirical_method_chaining/dev_samples/dev_chain_lengths_2018_',sample_num,'.csv', sep = ""))
  
  all_frequencies_2010 = get_sum_frequencies(df_2010)
  all_frequencies_2018 = get_sum_frequencies(df_2018)
  
  frequencies_g2_2010 = get_sum_frequencies(df_2010 %>% filter(chain_length > 1))
  frequencies_g2_2018 = get_sum_frequencies(df_2018 %>% filter(chain_length > 1))
  
  print(paste(round(frequencies_g2_2010/all_frequencies_2010,2), round(frequencies_g2_2018/all_frequencies_2018,2)))
 }

```


# Observation 2

```{r}

df_2010 = stars_method_chainings %>% filter(year==2010)
df_2018 = stars_method_chainings %>% filter(year==2018)

frequencies_g2_2010 = df_2010 %>% filter(chain_length > 1) %>% group_by(project_id) %>% summarize(chains_per_project=sum(frequency))
  frequencies_g2_2010$year=2010
  
  frequencies_g2_2018 = df_2018 %>% filter(chain_length > 1) %>% group_by(project_id) %>% summarize(chains_per_project=sum(frequency))
  frequencies_g2_2018$year=2018
  
  all = rbind(frequencies_g2_2010, frequencies_g2_2018)
  all$year = as.factor(all$year)
  counts <- table(all$year, all$chains_per_project)

  p <- all %>% filter(chains_per_project < 50) %>%
  ggplot( aes(x=chains_per_project, fill=year)) +
    geom_histogram( bin=25,color="#e9ecef", alpha=0.6, position = 'identity', aes(y=..count../sum(..count..))) +
    labs(fill="")
  
  print(p)

```



```{r}
df_2010 = stars_method_chainings %>% filter(year==2010)
frequencies_g2_2010 = df_2010 %>% filter(chain_length > 1) %>% group_by(project_id) %>% summarize(chains_per_project=sum(frequency))
  frequencies_g2_2010$year=2010
  
temp_java = java %>% select(id, size)

final_2010 = merge(x=temp_java,y=frequencies_g2_2010,by.x="id", by.y="project_id" )


df_2018 = stars_method_chainings %>% filter(year==2018)
frequencies_g2_2018 = df_2018 %>% filter(chain_length > 1) %>% group_by(project_id) %>% summarize(chains_per_project=sum(frequency))
  frequencies_g2_2018$year=2018
  final_2018 = merge(x=temp_java,y=frequencies_g2_2018,by.x="id", by.y="project_id" )
  
  all = rbind(final_2010, final_2018)
  
  ggplot(all, aes(x=size+1, y=chains_per_project, color=year)) + geom_point() + scale_x_continuous(trans='log2')+ scale_y_continuous(trans='log2')
```


```{r message=FALSE}
for (sample_num in 1:10){
  df_2010 = read_csv(paste('./reproductions/empirical_method_chaining/dev_samples/dev_chain_lengths_2010_',sample_num,'.csv', sep = ""), )
  df_2018 = read_csv(paste('./reproductions/empirical_method_chaining/dev_samples/dev_chain_lengths_2018_',sample_num,'.csv', sep = ""))
  
  frequencies_g2_2010 = df_2010 %>% filter(chain_length > 1) %>% group_by(project_id) %>% summarize(chains_per_project=sum(frequency))
  frequencies_g2_2010$year=2010
  
  frequencies_g2_2018 = df_2018 %>% filter(chain_length > 1) %>% group_by(project_id) %>% summarize(chains_per_project=sum(frequency))
  frequencies_g2_2018$year=2018
  
  all = rbind(frequencies_g2_2010, frequencies_g2_2018)
  all$year = as.factor(all$year)
  counts <- table(all$year, all$chains_per_project)

  p <- all %>% filter(chains_per_project < 50) %>%
  ggplot( aes(x=chains_per_project, fill=year)) +
    geom_histogram( bins = 25,color="#e9ecef", alpha=0.6, position = 'identity', aes(y=..count../sum(..count..))) +
    labs(fill="")
  
  print(p)
 }
```


```{r message=FALSE}
for (sample_num in 1:10){
  df_2010 = read_csv(paste('./reproductions/empirical_method_chaining/dev_samples/dev_chain_lengths_2010_',sample_num,'.csv', sep = ""), )
  df_2018 = read_csv(paste('./reproductions/empirical_method_chaining/dev_samples/dev_chain_lengths_2018_',sample_num,'.csv', sep = ""))
  
frequencies_g2_2010 = df_2010 %>% filter(chain_length > 1) %>% group_by(project_id) %>% summarize(chains_per_project=sum(frequency))
  frequencies_g2_2010$year=2010
  
temp_java = java %>% select(id, size)

final_2010 = merge(x=temp_java,y=frequencies_g2_2010,by.x="id", by.y="project_id" )

frequencies_g2_2018 = df_2018 %>% filter(chain_length > 1) %>% group_by(project_id) %>% summarize(chains_per_project=sum(frequency))
  frequencies_g2_2018$year=2018
  final_2018 = merge(x=temp_java,y=frequencies_g2_2018,by.x="id", by.y="project_id" )
  
  all = rbind(final_2010, final_2018)
  
  print(ggplot(all, aes(x=size+1, y=chains_per_project, color=year)) + geom_point() + scale_x_continuous(trans='log2')+ scale_y_continuous(trans='log2'))
 }
```


# Observation 4

```{r}

df_2010 = stars_method_chainings %>% filter(year==2010)
df_2018 = stars_method_chainings %>% filter(year==2018)

frequencies_g2_2010 = df_2010 %>% filter(chain_length > 1) %>% 
  group_by(project_id) %>% 
  summarize(frequency=sum(frequency)) %>%
  group_by(project_id, frequency) %>% summarise(count = n())
  
frequencies_g2_2010$year=2010

frequencies_g2_2018 = df_2018 %>% filter(chain_length > 1) %>% group_by(project_id) %>% summarize(frequency=sum(frequency))
frequencies_g2_2018$year=2018

all = rbind(frequencies_g2_2010, frequencies_g2_2018)
all$year = as.factor(all$year)
counts2010 <- table(all$year, all$frequency)

p <- all %>% filter(frequency < 8000) %>%
ggplot( aes(x=frequency, fill=year)) +
  geom_histogram( color="#e9ecef", alpha=0.6, position = 'identity', aes(y=..count../sum(..count..))) +
  labs(fill="")

print(p)

```
