---
title: "Project Selection Analysis"
output: html_notebook
---

```{r}
source("artifact/helpers.R")
source("artifact/latex-log.R")
initialize_log(name = "selection")

N_TOP_STARS = 1000
```

Here is the idea: The dataset is large and we need statistically sound ways to determine how to remove the uninteresting projects from it. As an example we can say that whether projects are developed or not depends on the number of commits they have. But where to draw the line and say projects with less than N commits are not considered developed. 

The obvious simple solution is to use the widely accepted 5% cutoff. We can illustrate the bad representativeness of the top stars projects by using the 5% cutoff calculated on the top stars projects, but on the entire population. 

> Finally, instead of 5% we can use the manual analysis of top starred projects to give us different number. However we have currently found this number to be at least 2 to 5% (it can be more, but due to the way we did the manual classification, these were the numbers of projects we saw). We can either ignore this, or we can redo the manual analysis. For now this document ignores this option.

# Cummulative graphs for various attributes

First, we plot cummulative graphs for the various attributes CodeDJ offers:

```{r}
# creates a cummulative table for the dataset and given column
create_cummulative_table = function(data, column, breaks) {
  column = as.symbol(column)
  data = data %>% select(!!column)
  data_rows = nrow(data)
  value = rep(0, length(breaks))
  pct = rep(0, length(breaks))
  for (i in 1:length(breaks)) {
    remaining = nrow(data %>% filter(!!column >= breaks[[i]]))
    value[[i]] = remaining
    pct[[i]] = remaining / data_rows
  }
  data.frame(
    cutoff = breaks,
    members = value,
    pct = pct
  )
}

prettify_value = function(x) {
  if (x == 1000)
    "1K"
  else if (x == 10000)
    "10K"
  else if (x == 100000)
    "100K"
  else if (x == 1000000)
    "1M"
  else if (x == 10000000)
    "10M"
  else if (x == 100000000)
    "100M"
  else if (x == 1000000000)
    "1B"
  else if (x == 10000000000)
    "10B"
  else if (x == 100000000000)
    "100B"
  else
    paste(x)
}

cutoff_all_f = function(x) { quantile(x, 0.05) }
cutoff_stars_f = min

# given a column name, create the cummulative graph for it
cummulative_graph = function(dall, dstars, col_name, title = col_name) {
  # get the cummulative tables    
  call = create_cummulative_table(dall, col_name, quantile(dall[[col_name]], 0:100 / 100))
  cstars = create_cummulative_table(dstars, col_name, quantile(dstars[[col_name]], 0:100 / 100))
  # merge them into a single data frame for easier printing
  call$source = rep("Dataset", nrow(call))
  cstars$source = rep("Top Stars", nrow(cstars))
  cboth = rbind(call, cstars)

  cutoff_all = cutoff_all_f(dall[[col_name]])
  if (cutoff_all == min(dall[[col_name]])) {
    cutoff_all = cutoff_all + 1
  }
  cutoff_stars = cutoff_stars_f(dstars[[col_name]])
  column = as.symbol(col_name)
  
  dcutoff = dall %>% filter(!!column >= cutoff_stars)
  
  cutoff_all_pct = nrow(dall %>% filter(!!column >= cutoff_all)) / nrow(dall)
  cutoff_stars_pct = nrow(dcutoff) / nrow(dall)
  
  ccutoff = create_cummulative_table(dcutoff, col_name, quantile(dcutoff[[col_name]], 0:100 / 100))
  ccutoff$source = "Remainder"
  cboth = rbind(cboth, ccutoff)
  
  v_breaks = sort(c(0, 0.25, 0.5, 0.75, 1, cutoff_all_pct, cutoff_stars_pct))
  v_labels = round(v_breaks * 100, 0)
  
  h_breaks = sort(c(0, 1, 10, 100, 1000, 10000, 100000, 1000000, 10000000, 100000000, 100000000000, cutoff_all, cutoff_stars))
  h_labels = sapply(h_breaks, prettify_value)
  
  plot = ggplot(cboth) +
    geom_line(aes(x = cutoff, y = pct, color = source)) +
    geom_vline(xintercept = cutoff_all, linetype = "dashed", color = "black") +
    geom_hline(yintercept = cutoff_all_pct, linetype = "dashed", color = "black") +
    geom_vline(xintercept = cutoff_stars, linetype = "dashed", color = "red") +
    geom_hline(yintercept = cutoff_stars_pct, linetype = "dashed", color = "red") +
    #scale_x_log10(breaks = c(0,1,10,100,1000,10000,100000), labels = c("0", "1","10", "100", "1K", "10K", "100K")) +
    scale_x_log10(breaks = h_breaks, labels = h_labels) +
    scale_y_continuous(breaks = v_breaks, labels = v_labels) + 
    scale_color_manual(values = c("black", "gray", "red")) +
    xlab(title) + ylab("%") +
    theme_classic()
  list(
  name = col_name, 
    title = title,
    plot = plot, cutoff_all = cutoff_all, cutoff_stars = cutoff_stars
  )
}
```

Let's do the graphs for the attributes we are looking into now for all three languages:

```{r}
columns = c("max_hindex1", "lifetime", "users", "locs", "snapshots", "commits")
names(columns) = c("C-Index", "Age", "Devs", "Locs", "Versions", "Commits")

language_plots = function(dataset, top_stars, columns) {
  cdata = list()
  for (name in names(columns)) {
    cdata[[name]] = cummulative_graph(dataset, top_stars, columns[[name]], title = name)
  }
  cdata  
}
```

```{r}
# java
java_dataset = java
java_topstars = java_dataset %>% filter(stars > 0) %>% arrange(desc(stars)) %>% head(N_TOP_STARS)
cjava = language_plots(java_dataset, java_topstars, columns)
#python
python_dataset = python
python_topstars = python_dataset %>% filter(stars > 0) %>% arrange(desc(stars)) %>% head(N_TOP_STARS)
cpython = language_plots(python_dataset, python_topstars, columns)
#js
js_dataset = js
js_topstars = js_dataset %>% filter(stars > 0) %>% arrange(desc(stars)) %>% head(N_TOP_STARS)
cjs = language_plots(js_dataset, js_topstars, columns)
```
### Java

```{r}
cjava[["C-Index"]]$plot
cjava[["Age"]]$plot
cjava[["Devs"]]$plot
cjava[["Locs"]]$plot
cjava[["Versions"]]$plot
cjava[["Commits"]]$plot
```

### Python

```{r}
cpython[["C-Index"]]$plot
cpython[["Age"]]$plot
cpython[["Devs"]]$plot
cpython[["Locs"]]$plot
cpython[["Versions"]]$plot
cpython[["Commits"]]$plot
```

### JavaScript

```{r}
cjs[["C-Index"]]$plot
cjs[["Age"]]$plot
cjs[["Devs"]]$plot
cjs[["Locs"]]$plot
cjs[["Versions"]]$plot
cjs[["Commits"]]$plot
```

# Datasets for analysis

For each language, we prepare the following three datasets:

- the top 1k stars, without the projects below the cutoff (i.e. ~5% of the top stars) (the red line after the *red* cutoff above)
- the full dataset without projects below the top stars 5% cutoff (the black line after the *red* cutoff above)
- the full dataset without lowest 5% projects (the black line after the black cutoff above)

These should roughly correspond to the top stars w/o misfits, the definitely interesting projects and the definitely uninteresting projects removed. 

```{r}
create_datasets = function(dataset, top_stars, cutoffs) {
  stars = top_stars
  good = dataset
  not_bad = dataset
  for (x in cutoffs) {
    colname = as.symbol(x$name)
    stars = stars %>% filter(!!colname >= x$cutoff_stars)
    good = good %>% filter(!!colname >= x$cutoff_stars)
    not_bad = not_bad %>% filter(!!colname >= x$cutoff_all)
  }
  cat(paste("top_stars:", nrow(stars), " (", nrow(stars) * 100 / nrow(top_stars), "%)\n"))
  cat(paste("good:", nrow(good), " (", nrow(good) * 100 / nrow(dataset), "%)\n"))
  cat(paste("not_bad:", nrow(good), " (", nrow(not_bad) * 100 / nrow(dataset), "%)\n"))
  list(stars = stars, good = good, not_bad = not_bad, cutoffs = cutoffs)
}
```

```{r}
cat("Java:\n");
java_datasets = create_datasets(java_dataset, java_topstars, cjava)
cat("Python:\n");
python_datasets = create_datasets(python_dataset, python_topstars, cjava)
cat("JS:\n");
js_datasets = create_datasets(js_dataset, js_topstars, cjava)
```
# Histograms

```{r}
get_selection_histogram = function(datasets, columns, title) {
  stars = datasets$stars %>% select(c("id", columns))
  good = datasets$good %>% select(c("id", columns))
  not_bad = datasets$not_bad %>% select(c("id", columns))
  # calculate the medians to be displayed too
  medians = data.frame(
    valueNotBad = sapply(names(columns), function(x) {median(not_bad[[x]])}),
    valueStars = sapply(names(columns), function(x) {median(stars[[x]])}),
    valueGood = sapply(names(columns), function(x) {median(good[[x]])}),
    variable = factor(names(columns), levels = rev(names(columns)))
  )
  # melt for the histograms
  stars = melt(stars, "id")
  good = melt(good, "id")
  not_bad = melt(not_bad, "id")
  stars$kind="stars"
  good$kind = "good"
  not_bad$kind = "not_bad"
  all = rbind(stars, good, not_bad)
  all$kind = factor(all$kind, levels = c("not_bad", "good", "stars"))
  all$variable = factor(all$variable, levels = rev(names(columns)))
  ggplot() +
    geom_density_ridges(data = all, aes(x = value, y = variable, color = kind, height = ..ndensity.., scale = 0.7), stat = "binline", bins = 50, draw_baseline = FALSE, alpha = 0.5, fill = NA) +
    geom_segment(data = medians, aes(x = valueNotBad, xend = valueNotBad, y = as.numeric(variable)-0.1, yend = as.numeric(variable) + 0.8), color = "black") +
    geom_segment(data = medians, aes(x = valueGood, xend = valueGood, y = as.numeric(variable)-0.1, yend = as.numeric(variable) + 0.8), color = "blue") +
    geom_segment(data = medians, aes(x = valueStars, xend = valueStars, y = as.numeric(variable)-0.1, yend = as.numeric(variable) + 0.8), color = "red") +
    theme_ridges() + 
    theme(legend.position = "bottom") +
    ylab("") + xlab("") +
    scale_x_continuous(breaks = c(1, 10, 100, 1e3, 1e4, 1e5, 1e6, 1e7, 1e8), labels = c("1","10", "100", "1k", "10k", "100k", "1m", "10m", "100m"), trans = "pseudo_log", limits=c(0, 10000000)) +
    scale_y_discrete(expand = expand_scale(mult = c(0.01, 0.25))) +
    scale_color_manual(values = c("black", "blue","red"), name = "") +
    theme(legend.position = c(0.6, 0.93), legend.direction = "vertical", plot.margin = margin(t = 0, b = 0, l =0, r = 0)) +
    ggtitle(title)
}
```

```{r}
get_selection_histogram(java_datasets, columns, "Java")
get_selection_histogram(python_datasets, columns, "Python")
get_selection_histogram(js_datasets, columns, "JavaScript")
```
An interpretation of these things is that the *not_bad* projects indeed contain a *lot* of stuff that is missing from the other two datasets (contrast this with the fact that these datasets already remove from 45 to 67% of the whole GitHub). The *good* and *stars* projects are a lot more similar (for one they start at the same position), however the starred projects are almost always quite biased towards more developed characteristics than is the norm in the datasets. 

# The missing pieces

The simplest one is to see the projects that in their attributes are better than the top stars as selecting by stars simply hides their existence:

```{r}
get_hidden_projects = function(datasets, columns) {
  hidden = datasets$good %>% select(c("id", "url", "stars", columns))
  stars = datasets$stars %>% select(columns)
  hidden$selected = rep(0, nrow(hidden))
  for (x in names(columns)) {
    cutoff = max(stars[[x]])
    hidden$selected = hidden$selected + (hidden[[x]] > cutoff)
  }
  hidden = hidden %>% filter(selected > 0)
  nrow(hidden)
}
get_hidden_projects(java_datasets, columns)
get_hidden_projects(python_datasets, columns)
get_hidden_projects(js_datasets, columns)
```

The numbers are small, and we can arguably leave it here. Glancing at the java projects reveals that while there are some genuine projects that are pretty developed and "excel" in some of the attributes, they just haven't amassed enough stars to be included in the top stars dataset. The others seem to be just copies of something else - interesting we do not have that something else in our dataset/stars (maybe?) - could be we do not have full dataset and there is very very few of these projects in reality. 

So arguably there is not much on the upper side that is missing from stars. Let's now turn our attention to the bottom part. 